{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear and Support Vector Modeling for Class Target (Python & SAS Viya)\n",
    "\n",
    "**EXAMPLE:** Linear and Support Vector Based Modeling for Class Target using Python & SAS Viya  \n",
    "**DATA SOURCE:**  \n",
    "Training Data: adult_train.csv, Testing Data: adult_test.csv   \n",
    "Becker, B. and Kohavi, R. (1996). Adult. UCI Machine Learning Repository. [Link](https://doi.org/10.24432/C5XW20)  \n",
    "                 \n",
    "**DESCRIPTION:** This template demonstrates a workflow for building predictive models in Python using non-tree-based modeling techniques such as Logistic Regression and Support Vector Machines (SVM).  \n",
    "**PURPOSE:** The goal is to predict the likelihood of a binary outcome, in this case, whether income exceeds $50K/yr.  \n",
    "**DETAILS:**  \n",
    "- Classification Models built include: Logistic Regression, Support Vector Machines (SVM), and Ensemble.  \n",
    "- Score the test data.\n",
    "- Model Assessment: Classification Report.\n",
    "- Model Comparison: Overlaid curves are plotted to assess the performance of each model in predicting events along with AUC score."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.ensemble import VotingClassifier\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sasviya.ml.linear_model import LogisticRegression\n",
    "from sasviya.ml.svm import SVC\n",
    "from sklearn.metrics import roc_curve, roc_auc_score, classification_report\n",
    "import seaborn as sn\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing\n",
    "- **Importing Data and Defining Variables**\n",
    "    - Load the dataset for both training and testing partitions.\n",
    "    - Define variables necessary for further analysis\n",
    "- **Imputation for Missing Values**\n",
    "    - Since the original data doesn't have missing values, let's insert missing values in the training partition for select interval variables to demonstrate an imputation technique."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the workspace path relative to the current working directory\n",
    "workspace = f\"{os.path.abspath('')}/../../data/\"\n",
    "\n",
    "# Importing Data and Defining Variables\n",
    "train_data = pd.read_csv(os.path.join(workspace, \"adult_train.csv\"))\n",
    "test_data = pd.read_csv(os.path.join(workspace, \"adult_test.csv\"))\n",
    "\n",
    "# Encode categorical target variable as binary labels\n",
    "train_data['target_binary'] = train_data['target'].replace({'<=50K': 0, '>50K': 1})\n",
    "test_data['target_binary'] = test_data['target'].replace({'<=50K': 0, '>50K': 1})\n",
    "\n",
    "# Define input features (X) and target variable (y)\n",
    "X_train = pd.get_dummies(train_data.drop(columns=['target', 'target_binary']))\n",
    "y_train = train_data['target_binary']\n",
    "X_test = pd.get_dummies(test_data.drop(columns=['target', 'target_binary']))\n",
    "y_test = test_data['target_binary']\n",
    "\n",
    "# Reindex the testing dataset with the columns from the training dataset\n",
    "X_test = X_test.reindex(columns=X_train.columns, fill_value=0)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Perform Imputation using Mean Strategy**\n",
    "- ***Note: Random missing values inserted for demonstration of imputation***\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Insert missing values randomly in the training data for demonstration purposes\n",
    "train_data_imputed = train_data.copy()\n",
    "np.random.seed(12345)  # Set seed for reproducibility\n",
    "train_data_imputed.loc[train_data_imputed.sample(frac=0.02).index, 'age'] = np.nan  # 2% missing values for 'age'\n",
    "train_data_imputed.loc[train_data_imputed.sample(frac=0.03).index, 'hours_per_week'] = np.nan  # 3% missing values for 'hours_per_week'\n",
    "\n",
    "# Print summary of missing values before imputation\n",
    "print(\"Summary of missing values before imputation:\")\n",
    "print(train_data_imputed.isnull().sum())\n",
    "\n",
    "# Imputation for missing values using mean strategy\n",
    "imputer = SimpleImputer(strategy='mean')\n",
    "train_data_imputed[['age', 'hours_per_week']] = imputer.fit_transform(train_data_imputed[['age', 'hours_per_week']])\n",
    "\n",
    "# Print summary of missing values after imputation\n",
    "print(\"\\nSummary of missing values after imputation:\")\n",
    "print(train_data_imputed.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Logistic Regression Model Training, Scoring and Evaluation\n",
    "For more information regarding SAS Viya Logistic Regression, refer to [this link](https://documentation.sas.com/?cdcId=workbenchcdc&cdcVersion=default&docsetId=explore&docsetTarget=n0110bswc89wqjn1tht4ceu4hs7y.htm).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Logistic Regression model\n",
    "sas_lr = LogisticRegression()\n",
    "\n",
    "# Fit the model\n",
    "sas_lr.fit(X_train, y_train)\n",
    "\n",
    "# Score on the test partition\n",
    "y_pred_log = sas_lr.predict(X_test)\n",
    "\n",
    "# Calculate predicted probabilities for the positive class ('>50K')\n",
    "y_pred_proba_log = sas_lr.predict_proba(X_test)['P_target_binary1'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Logistic Regression Model Evaluation**  \n",
    "&emsp; Generate Classification Report\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate confusion matrix \n",
    "class_report_log = classification_report(test_data['target_binary'], y_pred_log)\n",
    "\n",
    "# Print classification report for Logistic Regression\n",
    "print(\"\\nClassification Report:\")\n",
    "print(class_report_log)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVC Model Training, Scoring and Evaluation\n",
    "For more information regarding SAS Viya SVC, refer to [this link](https://documentation.sas.com/?cdcId=workbenchcdc&cdcVersion=default&docsetId=explore&docsetTarget=p1udx0532v47xfn1l3ix3scjh8uj.htm).\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVM model\n",
    "sas_svc_model = SVC()\n",
    "\n",
    "# Fit the model\n",
    "sas_svc_model.fit(X_train, train_data['target_binary']) \n",
    "\n",
    "# Score on the test partition\n",
    "y_pred_svm = sas_svc_model.predict(X_test)\n",
    "\n",
    "# Calculate predicted probabilities for the positive class ('>50K')\n",
    "y_pred_proba_svm = sas_svc_model.predict_proba(X_test)['P_target_binary1'].values"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SVM Model Evaluation**  \n",
    "&emsp; Generate Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification report \n",
    "class_report_svm = classification_report(test_data['target_binary'], y_pred_svm)\n",
    "\n",
    "# Print classification report for SVM\n",
    "print(\"\\nClassification Report for SVM:\")\n",
    "print(class_report_svm)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model\n",
    "##### Final prediction is based on averaged predicted probabilities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize ensemble model with logistic regression and SVM\n",
    "ensemble_model = VotingClassifier(estimators=[('logistic', sas_lr), ('svm', sas_svc_model)], voting='soft')\n",
    "\n",
    "# Fit the ensemble model\n",
    "ensemble_model.fit(X_train, y_train)\n",
    "\n",
    "# Score on the test partition\n",
    "y_pred_ensemble = ensemble_model.predict(X_test)\n",
    "\n",
    "# Calculate predicted probabilities for the positive class ('>50K')\n",
    "y_pred_proba_ensemble = ensemble_model.predict_proba(X_test)[:, 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Ensemble Model Evaluation**  \n",
    "&emsp; Generate Classification Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate classification report\n",
    "class_report_ensemble = classification_report(test_data['target_binary'], y_pred_ensemble)\n",
    "\n",
    "# Print classification report for Ensemble Model\n",
    "print(\"\\nClassification Report for Ensemble Model:\")\n",
    "print(class_report_ensemble)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Comparison - Overlaid ROC Curves\n",
    "##### Visualize ROC curves of multiple models on the same plot for easy comparison. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate ROC curve\n",
    "# Logistic Regression\n",
    "fpr_log, tpr_log, thresholds_log = roc_curve(test_data['target_binary'], y_pred_proba_log)\n",
    "roc_auc_log = roc_auc_score(test_data['target_binary'], y_pred_proba_log)\n",
    "# SVM\n",
    "fpr_svm, tpr_svm, _ = roc_curve(test_data['target_binary'], y_pred_proba_svm)\n",
    "roc_auc_svm = roc_auc_score(test_data['target_binary'], y_pred_proba_svm)\n",
    "# Ensemble\n",
    "fpr_ensemble, tpr_ensemble, _ = roc_curve(test_data['target_binary'], y_pred_proba_ensemble)\n",
    "roc_auc_ensemble = roc_auc_score(test_data['target_binary'], y_pred_proba_ensemble)\n",
    "\n",
    "# Plot ROC curves for Logistic Regression, SVM, and Ensemble models\n",
    "plt.figure(figsize=(10, 8))\n",
    "# Plot Logistic Regression ROC curve\n",
    "plt.plot(fpr_log, tpr_log, color='blue', lw=2, label='Logistic Regression ROC curve (AUC = %0.2f)' % roc_auc_log)\n",
    "# Plot SVM ROC curve\n",
    "plt.plot(fpr_svm, tpr_svm, color='green', lw=2, label='SVM ROC curve (AUC = %0.2f)' % roc_auc_svm)\n",
    "# Plot Ensemble Model ROC curve\n",
    "plt.plot(fpr_ensemble, tpr_ensemble, color='orange', lw=2, label='Ensemble Model ROC curve (AUC = %0.2f)' % roc_auc_ensemble)\n",
    "\n",
    "# Add labels and legend\n",
    "plt.plot([0, 1], [0, 1], color='gray', lw=1, linestyle='--')  # Diagonal reference line\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('ROC Curves for Logistic Regression, SVM, and Ensemble Models')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
