{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Linear Regression and SVM Modeling for Interval Target (SAS Viya)\n",
    "\n",
    "**EXAMPLE:** Linear and Support Vector Based Modeling for Interval Target using Python & SAS Viya  \n",
    "**DATA SOURCE:**  \n",
    "Data: bike_sharing_demand.csv   \n",
    "Fanaee-T, H. (2013). Bike Sharing Dataset. UCI Machine Learning Repository. [Link](https://doi.org/10.24432/C5W894) \n",
    "\n",
    "**DESCRIPTION:** This template demonstrates a workflow for building predictive models in Python using non-tree-based modeling techniques such as Linear Regression and Support Vector Machines (SVM).  \n",
    "**PURPOSE:** The goal is to predict the count of bikes rented per hour using various predictor variables, such as weather, season, temperature, hour, month, and weekday.  \n",
    "**DETAILS:**  \n",
    "- Models built include: Linear Regression, Support Vector Machines (SVM) & Ensemble\n",
    "- Preprocessing and Scoring the validation and test data\n",
    "- Model Assessment & Model Comparison: Mean Square Error\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import necessary libraries\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.feature_selection import SelectKBest, f_regression\n",
    "from sklearn.ensemble import VotingRegressor\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sasviya.ml.linear_model import LinearRegression\n",
    "from sasviya.ml.svm import SVR\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading and Preprocessing\n",
    "**Importing Data and Defining Variables**\n",
    "- Load the dataset for both training and testing partitions.\n",
    "- Define variables necessary for further analysis\n",
    "- Outlier Treatment\n",
    "- Feature Selection to identify the most relevant features for prediction.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct the workspace path\n",
    "workspace = f\"{os.path.abspath('')}/../../data/\"\n",
    "\n",
    "# Import Data and Define Variables\n",
    "data = pd.read_csv(workspace + \"bike_sharing_demand.csv\")\n",
    "\n",
    "# Split the data into Train, Validation, and Test sets (40% Train, 30% Validation, 30% Test)\n",
    "train_data, temp_test_data = train_test_split(data, test_size=0.6, random_state=42)\n",
    "val_data, test_data = train_test_split(temp_test_data, test_size=0.5, random_state=42)\n",
    "\n",
    "# Create X and y variables for modeling\n",
    "X_train, y_train = train_data.drop(columns=['count']), train_data['count']\n",
    "X_val, y_val = val_data.drop(columns=['count']), val_data['count']\n",
    "X_test, y_test = test_data.drop(columns=['count']), test_data['count']\n",
    "\n",
    "# Print first 5 rows of train dataset\n",
    "print(\"Top 5 rows of bikesharing train dataset:\")\n",
    "print(train_data.head(5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Treat Outliers**  \n",
    "The target variable \"count\" is highly skewed, and in order to address this, a logarithmic transformation is applied"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Perform log transformation on 'count' variable\n",
    "y_train = np.log1p(train_data['count'])\n",
    "y_val = np.log1p(val_data['count'])\n",
    "y_test = np.log1p(test_data['count'])\n",
    "\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 6))\n",
    "# Plot histogram of original 'count' variable\n",
    "axes[0].hist(train_data['count'], bins=30, alpha=0.5, color='blue', label='Original')\n",
    "axes[0].set_xlabel('Count')\n",
    "axes[0].set_ylabel('Frequency')\n",
    "axes[0].set_title('Distribution of Original Target \"count\" variable (Train)')\n",
    "axes[0].legend()\n",
    "\n",
    "# Plot histogram of log-transformed 'count' variable\n",
    "axes[1].hist(y_train, bins=30, alpha=0.5, color='green', label='Log Transformed')\n",
    "axes[1].set_xlabel('Log(Count + 1)')\n",
    "axes[1].set_ylabel('Frequency')\n",
    "axes[1].set_title('Distribution of Log Transformed Target \"count\" variable (Train)')\n",
    "axes[1].legend()\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Feature Selection**  \n",
    "&emsp; Identify the most relevant features for prediction.  \n",
    "&emsp; Feature selection is performed solely on the training set, and the same selected features are used across other partitions to prevent data leakage.   \n",
    "&emsp; SelectKBest technique is used to select the top k features based on univariate statistical tests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Exclude 'date' from X_train\n",
    "X_train_subset = X_train.drop(columns=['date'])\n",
    "\n",
    "# Perform feature selection using SelectKBest technique that selects the top k features based on univariate statistical tests\n",
    "selector = SelectKBest(score_func=f_regression, k=5)  # Select top 5 features\n",
    "X_train_selected = selector.fit_transform(X_train_subset, y_train)\n",
    "\n",
    "# Get selected feature names\n",
    "selected_features = X_train_subset.columns[selector.get_support()]\n",
    "\n",
    "# Print selected feature names\n",
    "print(\"Selected Features:\", selected_features)\n",
    "\n",
    "# Subset all partitions using selected features\n",
    "X_train_selected = pd.DataFrame(X_train_selected, columns=selected_features)\n",
    "X_val_selected = X_val[selected_features]\n",
    "X_test_selected = X_test[selected_features]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linear Regression Model Training, Scoring and Evaluation\n",
    "For more information regarding SAS Viya Linear Regression, refer to [this link](https://documentation.sas.com/?cdcId=workbenchcdc&cdcVersion=default&docsetId=explore&docsetTarget=p0kx8n36nycmj0n1h1o8d3tqfxc3.htm).\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize Linear Regression model\n",
    "sas_lr = LinearRegression()\n",
    "\n",
    "# Fit the model\n",
    "sas_lr.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_train_pred = sas_lr.predict(X_train_selected)\n",
    "\n",
    "# Calculate MSE on training partition\n",
    "mse_train = mean_squared_error(y_train, y_train_pred)\n",
    "print(f\"Training Mean Squared Error (Linear Regression): {mse_train:.3f}\")\n",
    "\n",
    "# Make predictions on validation data\n",
    "y_val_pred = sas_lr.predict(X_val_selected)\n",
    "\n",
    "# Calculate MSE on validation partition\n",
    "mse_val = mean_squared_error(y_val, y_val_pred)\n",
    "print(f\"Validation Mean Squared Error (Linear Regression): {mse_val:.3f}\")\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred = sas_lr.predict(X_test_selected)\n",
    "\n",
    "# Calculate MSE on test partition\n",
    "mse_test = mean_squared_error(y_test, y_test_pred)\n",
    "print(f\"Test Mean Squared Error (Linear Regression): {mse_test:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### SVM Model Training, Scoring and Evaluation\n",
    "NOTE: An SVM with an interval target is often referred to as Support Vector Regression (SVR)  \n",
    "For more information regarding SAS Viya SVR, refer to [this link](https://documentation.sas.com/?cdcId=workbenchcdc&cdcVersion=default&docsetId=explore&docsetTarget=p14qlscxhb7i70n196xmpynf7lay.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Initialize SVM model\n",
    "sas_svm_model = SVR()\n",
    "\n",
    "# Fit the SVM model\n",
    "sas_svm_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on training data\n",
    "y_train_pred_svm = sas_svm_model.predict(X_train_selected)\n",
    "\n",
    "# Calculate MSE on training partition\n",
    "mse_train_svm = mean_squared_error(y_train, y_train_pred_svm)\n",
    "print(f\"Training Mean Squared Error (SVM): {mse_train_svm:.3f}\")\n",
    "\n",
    "# Make predictions on validation data\n",
    "y_val_pred_svm = sas_svm_model.predict(X_val_selected)\n",
    "\n",
    "# Calculate MSE on validation partition\n",
    "mse_val_svm = mean_squared_error(y_val, y_val_pred_svm)\n",
    "print(f\"Validation Mean Squared Error (SVM): {mse_val_svm:.3f}\")\n",
    "\n",
    "# Make predictions on test data\n",
    "y_test_pred_svm = sas_svm_model.predict(X_test_selected)\n",
    "\n",
    "# Calculate MSE on test partition\n",
    "mse_test_svm = mean_squared_error(y_test, y_test_pred_svm)\n",
    "print(f\"Test Mean Squared Error (SVM): {mse_test_svm:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ensemble Model Training, Scoring, and Evaluation\n",
    "Combine predictions from Linear Regression and SVM using simple averaging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ensemble model combining Linear Regression and SVM predictions\n",
    "ensemble_model = VotingRegressor([('lr', sas_lr), ('svm', sas_svm_model)])\n",
    "ensemble_model.fit(X_train_selected, y_train)\n",
    "\n",
    "# Make predictions on validation and test data for the ensemble model\n",
    "y_train_pred_ensemble = ensemble_model.predict(X_train_selected)\n",
    "y_val_pred_ensemble = ensemble_model.predict(X_val_selected)\n",
    "y_test_pred_ensemble = ensemble_model.predict(X_test_selected)\n",
    "\n",
    "# Calculate MSE on training partition for the ensemble model\n",
    "mse_train_ensemble = mean_squared_error(y_train, y_train_pred_ensemble)\n",
    "print(f\"Training Mean Squared Error (Ensemble): {mse_train_ensemble:.3f}\")\n",
    "\n",
    "# Calculate MSE on validation partition for the ensemble model\n",
    "mse_val_ensemble = mean_squared_error(y_val, y_val_pred_ensemble)\n",
    "print(f\"Validation Mean Squared Error (Ensemble): {mse_val_ensemble:.3f}\")\n",
    "\n",
    "# Calculate MSE on test partition for the ensemble model\n",
    "mse_test_ensemble = mean_squared_error(y_test, y_test_pred_ensemble)\n",
    "print(f\"Test Mean Squared Error (Ensemble): {mse_test_ensemble:.3f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Model Assessment\n",
    "Examine the distribution of residuals to assess model assumptions and identify any bias or variance issues"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate residuals for Linear Regression, SVM, and Ensemble models on the validation data\n",
    "residuals_lr = y_val - y_val_pred\n",
    "residuals_svm = y_val - y_val_pred_svm\n",
    "residuals_ensemble = y_val - y_val_pred_ensemble\n",
    "\n",
    "# Plot the distribution of residuals for all three models\n",
    "plt.figure(figsize=(12, 8))\n",
    "\n",
    "# Plot residuals for Linear Regression model\n",
    "sns.histplot(residuals_lr, kde=True, color='red', label='Linear Regression Residuals')\n",
    "\n",
    "# Plot residuals for SVM model\n",
    "sns.histplot(residuals_svm, kde=True, color='green', label='SVM Residuals')\n",
    "\n",
    "# Plot residuals for Ensemble model\n",
    "sns.histplot(residuals_ensemble, kde=True, color='blue', label='Ensemble Residuals')\n",
    "\n",
    "# Set labels and title\n",
    "plt.xlabel('Residuals')\n",
    "plt.ylabel('Frequency')\n",
    "plt.title('Distribution of Residuals: Linear Regression vs. SVM vs. Ensemble')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Overall Model Comparison\n",
    "Compare Mean Squared Error (MSE) across the models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define models and corresponding MSE values\n",
    "models = ['Linear Regression', 'SVM', 'Ensemble']\n",
    "mse_train_values = [mse_train, mse_train_svm, mse_train_ensemble]\n",
    "mse_val_values = [mse_val, mse_val_svm, mse_val_ensemble]\n",
    "mse_test_values = [mse_test, mse_test_svm, mse_test_ensemble]\n",
    "\n",
    "# Plot MSE for all models across validation and test partitions\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(models, mse_train_values, marker='o', label='Training MSE', color='blue')\n",
    "plt.plot(models, mse_val_values, marker='s', label='Validation MSE', color='green')\n",
    "plt.plot(models, mse_test_values, marker='x', label='Test MSE', color='red')\n",
    "\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Mean Squared Error')\n",
    "plt.title('Comparison of Mean Squared Error (MSE) for Linear Regression, SVM, and Ensemble')\n",
    "plt.legend()\n",
    "plt.grid(True)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Linear Regression is the champion model because it has the lowest MSE."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
