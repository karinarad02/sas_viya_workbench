{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## LogisticRegression and others from SAS® Viya® on Heart Disease\n",
    "### Source\n",
    "This example is adapted from [Heart Disease UCI](https://www.kaggle.com/code/harshalgadhe/heart-disease-uci) by Harshal Gadhe.\n",
    "\n",
    "### Data Preparation\n",
    "#### About the data set\n",
    "The original data contains 76 different attributes of patients from four different hospital databases.  The goal is to determine if the attributes can be used to predict whether patients are diagnosed with heart disease.  However, this data has been subset to contain only 14 factors from only the Cleveland database.  The variables included and their interpretations are:\n",
    "- age\n",
    "- trestbps: resting blood pressure\n",
    "- chol: serum cholesterol\n",
    "- thalch: maximum heart rate achieved\n",
    "- ca: number of major vessels (0-3) colored by flourosopy\n",
    "- sex\n",
    "- cp: chest pain type\n",
    "- exang: exercise-induced angina\n",
    "- slope: slope of the peak exercise ST segment\n",
    "- thal:  thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n",
    "- restecg: resting electrocardiographic results\n",
    "- fbs: fasting blood sugar\n",
    "- target: diagnosis of heart disease\n",
    "- oldpeak: ST depression induced by exercise relative to rest\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sn\n",
    "\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "pd.options.mode.chained_assignment = None"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "workspace=f'{os.path.abspath(\"\")}/../data/'\n",
    "heart_df = pd.read_csv(workspace + \"heart_disease.csv\")\n",
    "heart_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(workspace)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "We will start by getting some general characteristics about the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing NaN values with mean\n",
    "In examining the data, we see there are some missing values.  We will replace those with the mean for the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_sum_null = heart_df.isnull().sum()\n",
    "print(cols_sum_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasnull_cols = cols_sum_null[cols_sum_null != 0]\n",
    "for col in hasnull_cols.index:\n",
    "    mean = heart_df[col].mean()\n",
    "    heart_df[col].fillna(mean, inplace=True)\n",
    "heart_df.isnull().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.corr()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "In order to get a better sense of the data, we will look at a variety of plots:\n",
    "- a pairplot of continuous features\n",
    "- a heatmap of correlations\n",
    "- scatterplots of target versus each factor\n",
    "- a histogram of target's values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_threshold = 8\n",
    "quantitative = [c for c in heart_df.columns if len(heart_df[c].unique()) > cat_threshold]\n",
    "\n",
    "sn.pairplot(heart_df[quantitative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,10))\n",
    "sn.heatmap(heart_df.corr(),annot=True,cmap=plt.cm.plasma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15,15))\n",
    "for i in range(len(heart_df.columns)-1):\n",
    "    plt.subplot(5, 3, i+1)\n",
    "    sn.scatterplot(data=heart_df, x='target', y=heart_df.columns[i], hue='target')\n",
    "    plt.xticks([0, 1])\n",
    "plt.tight_layout(pad=4.0)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sn.countplot(x='target', data=heart_df)\n",
    "plt.grid()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Training the Model\n",
    "For details about using the classes in `sasviya.ml` see the [Python API documentation](https://documentation.sas.com/?cdcId=workbenchcdc&cdcVersion=default&docsetId=explore&docsetTarget=titlepage.htm).\n",
    "\n",
    "#### Data preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc=StandardScaler()\n",
    "X=heart_df.drop('target',axis=1)\n",
    "Y=heart_df['target']\n",
    "heart_df=sc.fit(X).transform(X)\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating training and test data\n",
    "We split the original data by putting 75% into the training set and 25% into the test set. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "X_train,X_test,y_train,y_test=train_test_split(X,Y,test_size=0.25,random_state=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "####  Training the model for six different alogorithms\n",
    "We will train six different models against the training set: LogisticRegression, DecisionTreeClassifier, SVC, ForestClassifier, KNeighborsClassifier, and GaussianNB. The latter two are sklearn classifiers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sasviya.ml.linear_model import LogisticRegression\n",
    "from sasviya.ml.tree import DecisionTreeClassifier\n",
    "from sasviya.ml.svm import SVC\n",
    "from sasviya.ml.tree import ForestClassifier\n",
    "\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import GaussianNB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def model(X_train,y_train):\n",
    "    models=[]\n",
    "\n",
    "    lr = LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "        tol=1e-4,\n",
    "        max_iter=1000)\n",
    "    lr.fit(X_train,y_train)\n",
    "    models.append(lr)\n",
    "\n",
    "    tree=DecisionTreeClassifier()\n",
    "    tree.fit(X_train,y_train)\n",
    "    models.append(tree)\n",
    "\n",
    "    svm=SVC(kernel='rbf', coef0=0.1, C=1.0)\n",
    "\n",
    "    svm.fit(X_train,y_train)\n",
    "    models.append(svm)\n",
    "\n",
    "    knn=KNeighborsClassifier(n_neighbors=5)\n",
    "    knn.fit(X_train,y_train)\n",
    "    models.append(knn)\n",
    "\n",
    "    rfc=ForestClassifier()\n",
    "    rfc.fit(X_train,y_train)\n",
    "    models.append(rfc)\n",
    "\n",
    "    nb=GaussianNB()\n",
    "    nb.fit(X_train,y_train)\n",
    "    models.append(nb)\n",
    "\n",
    "    return models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "models=model(X_train,y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gathering the accuracy scores\n",
    "As we just ran six models, we should examine how well they did relative to each other.  For each, we will gather the accuracy scores for the training and test data and add them into a summary dataframe."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "train_accuracy=[]\n",
    "test_accuracy=[]\n",
    "\n",
    "for m in models:\n",
    "    train_accuracy.append(round(m.score(X_train, y_train),2))\n",
    "    test_accuracy.append(round(m.score(X_test, y_test),2))\n",
    "\n",
    "Accuracy_score=pd.DataFrame({\n",
    "    'Model': [str(m.__repr__()).split('(')[0]for m in models],\n",
    "    'Train_Accuracy':train_accuracy,\n",
    "    'Test_Accuracy':test_accuracy\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Finding the Best Model\n",
    "After displaying the table of all accuracy scores for the training and test data, we will graph the test accuracy for each algorithm to see how they all fared on the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "Accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(12,6))\n",
    "plt.plot(Accuracy_score['Model'],Accuracy_score['Test_Accuracy'],marker='x',color='red')\n",
    "plt.xlabel('Model')\n",
    "plt.ylabel('Test Accuracy')\n",
    "plt.title('Test Accuracy by Model')\n",
    "plt.grid()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
