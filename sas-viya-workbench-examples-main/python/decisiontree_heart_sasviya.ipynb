{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DecisionTreeClassifier and others from SAS® Viya® on Heart Disease\n",
    "### Source\n",
    "This example is adapted from [Heart Disease prediction Random forest Classifier](https://www.kaggle.com/code/mruanova/heart-disease-prediction-random-forest-classifier) by Mau Rua.\n",
    "\n",
    "### Data Preparation\n",
    "#### About the data set\n",
    "The original data contains 76 different attributes of patients from four different hospital databases.  The goal is to determine if the attributes can be used to predict whether patients are diagnosed with heart disease.  However, this data has been subset to contain only 14 factors from only the Cleveland database.  The variables included and their interpretations are:\n",
    "- age\n",
    "- trestbps: resting blood pressure\n",
    "- chol: serum cholesterol\n",
    "- thalch: maximum heart rate achieved\n",
    "- ca: number of major vessels (0-3) colored by flourosopy\n",
    "- sex\n",
    "- cp: chest pain type\n",
    "- exang: exercise-induced angina\n",
    "- slope: slope of the peak exercise ST segment\n",
    "- thal:  thalassemia (3 = normal; 6 = fixed defect; 7 = reversable defect)\n",
    "- restecg: resting electrocardiographic results\n",
    "- fbs: fasting blood sugar\n",
    "- target: diagnosis of heart disease \n",
    "- oldpeak: ST depression induced by exercise relative to rest"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Importing the data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import warnings\n",
    "\n",
    "from sasviya.ml.linear_model import LogisticRegression\n",
    "from sasviya.ml.tree import DecisionTreeClassifier, ForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import seaborn as sn\n",
    "\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "pd.options.mode.chained_assignment = None\n",
    "warnings.filterwarnings(\"ignore\", category=RuntimeWarning)\n",
    "warnings.filterwarnings(\"ignore\", category=UserWarning)\n",
    "warnings.simplefilter(action='ignore', category=FutureWarning)\n",
    "\n",
    "workspace=f'{os.path.abspath(\"\")}/../data/'\n",
    "heart_df=pd.read_csv(workspace+'heart_disease.csv')\n",
    "heart_df.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing\n",
    "We will start by getting some general characteristics about the data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "heart_df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Replacing NaN values with mean\n",
    "In examining the data, we see there are some missing values.  We will replace those with the mean for the column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols_sum_null = heart_df.isnull().sum()\n",
    "print('Missing value counts (before imputation)\\n', cols_sum_null)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "hasnull_cols = cols_sum_null[cols_sum_null != 0]\n",
    "for col in hasnull_cols.index:\n",
    "    mean = heart_df[col].mean()\n",
    "    heart_df[col].fillna(mean, inplace=True)\n",
    "print('Missing value counts (after imputation)\\n', heart_df.isnull().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing the data\n",
    "To help understand the data, we will generate some graphs and perform some additional analysis.\n",
    "- a histogram of target for \"Heart Disease\" versus \"No disease\"\n",
    "- a pie chart visualization of the same information\n",
    "- a pairplot of quantitative features\n",
    "- a heatmap of feature correlations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "disease = len(heart_df[heart_df['target'] == 1])\n",
    "no_disease = len(heart_df[heart_df['target']== 0])\n",
    "\n",
    "x = [disease, no_disease]\n",
    "y = ['Heart Disease', 'No Disease']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(6, 2))\n",
    "y_pos = np.arange(len(y))\n",
    "ax.barh(y_pos, x, align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(y)\n",
    "ax.invert_yaxis() # labels read top-to-bottom\n",
    "ax.set_xlabel('Count')\n",
    "ax.set_title('Target')\n",
    "for i, v in enumerate(x):\n",
    "    ax.text(v, i, str(v), color='black', va='center', fontweight='normal')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig1, ax1 = plt.subplots(figsize=(4, 4))\n",
    "ax1.pie(x,  labels=y, autopct='%1.1f%%', startangle=90)\n",
    "ax1.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "plt.title('Target categories', size=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#identify quantitative (continuous) features based on number of unique categories\n",
    "cat_threshold = 8\n",
    "qualitative = [c for c in heart_df.columns if len(heart_df[c].unique()) <= cat_threshold]\n",
    "quantitative = [c for c in heart_df.columns if len(heart_df[c].unique()) > cat_threshold]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Qualitative features:\\n', qualitative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Quantitative features:\\n', quantitative)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "sn.pairplot(heart_df[quantitative])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corr = heart_df.corr()\n",
    "f,ax = plt.subplots(figsize=(8, 8))\n",
    "hm = sn.heatmap(corr, square=True, ax=ax, annot=True, cmap='Pastel1_r', fmt='.2f', annot_kws={'size':8})\n",
    "plt.title('Feature Correlations', size=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Creating training and test data\n",
    "We split the original data by putting 80% into the training set and 20% into the test set.  We will also examine the shape of the full data and the two new subsets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = heart_df.drop('target', axis=1)\n",
    "y = heart_df['target']\n",
    "print('Full data')\n",
    "print('Shape of X and y respectively :', X.shape, y.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
    "print('After split')\n",
    "print('Shape of X and y respectively (train) :', X_train.shape, y_train.shape)\n",
    "print('Shape of X and y respectively (test) :', X_test.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building and Training Models with Four Different Alogorithms\n",
    "We will train four different models against the training set: LogisticRegression, DecisionTreeClassifier, ForestClassifier, and GradientBoostingClassifier.  In each case, the following will also be examined for each run:\n",
    "- Model accuracy\n",
    "- Confusion matrix\n",
    "- ROC plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Common model fitting and assessment code\n",
    "\n",
    "def fit_model(X_train, y_train, X_test, y_test, model):\n",
    "    print(model.name.split('_')[0], 'Accuracy\\n')\n",
    "    model.fit(X_train, y_train)\n",
    "    y_pred_test = model.predict(X_test)\n",
    "\n",
    "    train_score =  model.score(X_train, y_train)\n",
    "    test_score = model.score(X_test, y_test)\n",
    "\n",
    "    print(f'Training accuracy: {train_score:.2f}')\n",
    "    print(f'Test accuracy: {test_score:.2f}')\n",
    "\n",
    "    return y_pred_test, test_score\n",
    "\n",
    "\n",
    "def accuracy_report(y_test, y_pred_test, model):\n",
    "    output = pd.DataFrame({'Predicted':y_pred_test}) # Heart-Disease yes or no? 1/0\n",
    "    people = output.loc[output.Predicted == 1][\"Predicted\"]\n",
    "    rate_people = 0\n",
    "    if len(people) > 0 :\n",
    "        rate_people = len(people)/len(output)\n",
    "    print(f\"% of people predicted with heart-disease: {rate_people*100:.2f}\\n\")\n",
    "    print('Classification Report for', model.name.split('_')[0], '\\n', classification_report(y_test,y_pred_test))\n",
    "\n",
    "\n",
    "def confusion_plot(y_test, y_pred_test, model):\n",
    "    confusion_results = confusion_matrix(y_test,y_pred_test)\n",
    "    class_names = [0,1]\n",
    "    fig,ax = plt.subplots() #\n",
    "    tick_marks = np.arange(len(class_names))\n",
    "    plt.xticks(tick_marks,class_names)\n",
    "    plt.yticks(tick_marks,class_names)\n",
    "    sn.heatmap(pd.DataFrame(confusion_results), annot = True, cmap = 'Pastel1_r', fmt = 'g')\n",
    "    ax.xaxis.set_label_position('top')\n",
    "    plt.tight_layout()\n",
    "    plt.title('Confusion Matrix for ' + model.name.split('_')[0])\n",
    "    plt.ylabel('Actual label')\n",
    "    plt.xlabel('Predicted label')\n",
    "\n",
    "def roc_plot(X_test, y_test, model):\n",
    "    probs = model.predict_proba(X_test).to_numpy()\n",
    "    preds = probs[:,1]\n",
    "    fpr, tpr, threshold = roc_curve(y_test, preds)\n",
    "    roc_auc = auc(fpr, tpr)\n",
    "\n",
    "    plt.figure()\n",
    "    plt.plot(fpr, tpr, label='Model (area = %0.3f)' % roc_auc)\n",
    "    plt.plot([0, 1], [0, 1],'r--')\n",
    "    plt.xlim([0.0, 1.0])\n",
    "    plt.ylim([0.0, 1.05])\n",
    "    plt.xlabel('False Positive Rate')\n",
    "    plt.ylabel('True Positive Rate')\n",
    "    plt.title('ROC for ' + model.name.split('_')[0])\n",
    "    plt.legend(loc=\"lower right\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### LogisticRegression\n",
    "\n",
    "For details about using the `LogisticRegression` class in the `sasviya` package, see the [LogisticRegression documentation](https://documentation.sas.com/?cdcId=workbenchcdc&cdcVersion=default&docsetId=explore&docsetTarget=n0110bswc89wqjn1tht4ceu4hs7y.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "logreg = LogisticRegression(\n",
    "        solver='lbfgs',\n",
    "        tol=1e-4,\n",
    "        max_iter=1000)\n",
    "\n",
    "y_pred_test, score_logreg = fit_model(X_train, y_train, X_test, y_test, model=logreg)\n",
    "accuracy_report(y_test, y_pred_test, model=logreg)\n",
    "confusion_plot(y_test, y_pred_test, model=logreg)\n",
    "roc_plot(X_test, y_test, model=logreg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### DecisionTreeClassifier\n",
    "\n",
    "For details about using the `DecisionTreeClassifier` class in the `sasviya` package, see the [DecisionTreeClassifier documentation](https://documentation.sas.com/?cdcId=workbenchcdc&cdcVersion=default&docsetId=explore&docsetTarget=p14rqs4yfhf5bcn1js9nlfgzx795.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dt = DecisionTreeClassifier(max_depth=5)\n",
    "y_pred_test, score_dtc = fit_model(X_train, y_train, X_test, y_test, model=dt)\n",
    "accuracy_report(y_test, y_pred_test, model=dt)\n",
    "confusion_plot(y_test, y_pred_test, model=dt)\n",
    "roc_plot(X_test, y_test, model=dt)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### ForestClassifier\n",
    "\n",
    "For details about using the `ForestClassifier` class in the `sasviya` package, see the [ForestClassifier documentation](https://documentation.sas.com/?cdcId=workbenchcdc&cdcVersion=default&docsetId=explore&docsetTarget=p04zhxjh60eutqn1t40f0104gw42.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fc = ForestClassifier(\n",
    "    n_estimators=100,\n",
    "    max_depth=5,\n",
    "    min_samples_leaf=1,\n",
    "    max_features=None,\n",
    "    criterion='gini',\n",
    "    random_state=1\n",
    ")\n",
    "\n",
    "y_pred_test, score_fc = fit_model(X_train, y_train, X_test, y_test, model=fc)\n",
    "accuracy_report(y_test, y_pred_test, model=fc)\n",
    "confusion_plot(y_test, y_pred_test, model=fc)\n",
    "roc_plot(X_test, y_test, model=fc)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### GradientBoostingClassifier\n",
    "\n",
    "For details about using the `GradientBoostingClassifier` class in the `sasviya` package, see the [GradientBoostingClassifier documentation](https://documentation.sas.com/?cdcId=workbenchcdc&cdcVersion=default&docsetId=explore&docsetTarget=n1kiea90s0276wn1xr0ig0hvkix6.htm)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gb = GradientBoostingClassifier(n_estimators=100,\n",
    "                                max_depth=5,\n",
    "                                min_samples_leaf=1,\n",
    "                                max_features=None,\n",
    "                                learning_rate = 0.1,\n",
    "                                subsample = 1.0,\n",
    "                                random_state=1)\n",
    "\n",
    "y_pred_test, score_gbc = fit_model(X_train, y_train, X_test, y_test, model=gb)\n",
    "accuracy_report(y_test, y_pred_test, model=gb)\n",
    "confusion_plot(y_test, y_pred_test, model=gb)\n",
    "roc_plot(X_test, y_test, model=gb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Summarizing the results\n",
    "Using a histogram, we will examine the accuracy scores of each model and identify which performed best on this training and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithms = ['LogisticRegression', 'GradientBoosting', 'Forest', 'DecisionTree']\n",
    "scores = [round(s,2) for s in [score_logreg, score_gbc, score_fc, score_dtc]]\n",
    "\n",
    "scores_df = pd.DataFrame(zip(algorithms, scores))\n",
    "scores_df.columns = ['Name','Test Accuracy']\n",
    "\n",
    "scores_df.sort_values(by='Test Accuracy', inplace=True, ascending = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.rcdefaults()\n",
    "fig, ax = plt.subplots()\n",
    "\n",
    "y_pos = np.arange(len(scores_df)) # scores\n",
    "bars = ax.barh(y_pos, scores_df['Test Accuracy'], align='center')\n",
    "ax.set_yticks(y_pos)\n",
    "ax.set_yticklabels(scores_df['Name'])\n",
    "ax.invert_yaxis() # labels read top-to-bottom\n",
    "ax.set_xlabel('Test Accuracy')\n",
    "ax.set_title('Which algorithm is best?')\n",
    "ax.bar_label(bars)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
